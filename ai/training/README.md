# Training Scripts for News Embeddings

Este directorio contiene scripts para entrenar modelos de embeddings personalizados en el corpus de noticias.

## Prerequisitos

1. **Exportar corpus**: Primero debes exportar art√≠culos desde la base de datos principal al corpus:
   ```bash
   # Exportar todos los art√≠culos
   uv run news export corpus

   # O exportar con filtros
   uv run news export corpus --domain diariolibre.com --limit 1000
   ```

2. **Verificar distribuci√≥n**: Es importante tener art√≠culos de m√∫ltiples categor√≠as y subcategor√≠as:
   ```bash
   python ai/training/analysis.py
   ```

   Esto mostrar√°:
   - N√∫mero de noticias por categor√≠a/subcategor√≠a
   - Total de pares de entrenamiento potenciales

## Scripts Disponibles

### 1. `analysis.py` - An√°lisis del Corpus

Muestra la distribuci√≥n de art√≠culos por categor√≠a y subcategor√≠a.

```bash
python ai/training/analysis.py
```

**Salida esperada:**
```
=== Distribuci√≥n de datos ===

üìÅ Pol√≠tica: 150 noticias
  ‚îú‚îÄ Nacional: 80 noticias
  ‚îú‚îÄ Internacional: 70 noticias

üìÅ Deportes: 100 noticias
  ‚îú‚îÄ B√©isbol: 50 noticias
  ‚îú‚îÄ F√∫tbol: 30 noticias
  ‚îú‚îÄ Baloncesto: 20 noticias

üìä Total noticias: 250
üìä Pares potenciales (aprox): 1500
```

### 2. `embeddings/simple.py` - Entrenamiento Jer√°rquico Simple

Estrategia de entrenamiento con niveles de similaridad:
- **Misma subcategor√≠a**: label = 0.95 (muy similares)
- **Misma categor√≠a, diferente subcategor√≠a**: label = 0.7 (relacionados)
- **Diferente categor√≠a**: label = 0.0 (negativos)
- **T√≠tulo-contenido original**: label = 1.0 (id√©nticos)

```bash
python ai/training/embeddings/simple.py
```

**Par√°metros configurables** (editar en el script):
- `base_model`: Modelo base a fine-tunear (default: `paraphrase-multilingual-MiniLM-L12-v2`)
- `epochs`: N√∫mero de √©pocas (default: 4)
- `batch_size`: Tama√±o de batch (default: 16)

**Output**: Modelo guardado en `ai/models/embeddings/news-embeddings-simple-TIMESTAMP/`

### 3. `embeddings/controlled_ratios.py` - Entrenamiento Balanceado

Similar al simple pero con control fino de ratios entre tipos de pares.

```bash
python ai/training/embeddings/controlled_ratios.py
```

**Par√°metros configurables**:
- `ratio_same_subcat`: Pares de misma subcategor√≠a por art√≠culo (default: 2)
- `ratio_same_cat`: Pares de misma categor√≠a por art√≠culo (default: 1)
- `ratio_different_cat`: Pares de categor√≠as diferentes por art√≠culo (default: 2)

**Output**: Modelo guardado en `ai/models/embeddings/news-embeddings-balanced-TIMESTAMP/`

## Recomendaciones

### Corpus M√≠nimo Recomendado

Para un entrenamiento efectivo:
- **M√≠nimo**: 100+ art√≠culos con al menos 3 categor√≠as diferentes
- **√ìptimo**: 500+ art√≠culos con 5+ categor√≠as, cada una con 2+ subcategor√≠as
- **Ideal**: 1000+ art√≠culos con distribuci√≥n balanceada

### Ajuste de Hiperpar√°metros

**Si tienes pocas noticias** (<200):
```python
epochs=2-3
batch_size=8
```

**Si tienes bastantes noticias** (200-1000):
```python
epochs=4-5
batch_size=16
```

**Si tienes muchas noticias** (>1000):
```python
epochs=3-4
batch_size=32
```

### Selecci√≥n de Estrategia

**Usa `simple.py` si:**
- Tienes distribuci√≥n desbalanceada de categor√≠as
- Quieres m√°s control autom√°tico
- Primer experimento

**Usa `controlled_ratios.py` si:**
- Necesitas ajustar balance de pares positivos/negativos
- Ya probaste simple y quieres optimizar
- Tienes problemas de overfitting o underfitting

## Uso del Modelo Entrenado

Una vez entrenado, puedes usar el modelo as√≠:

```python
from sentence_transformers import SentenceTransformer

# Cargar modelo entrenado
model = SentenceTransformer('ai/models/embeddings/news-embeddings-simple-TIMESTAMP')

# Generar embeddings
texts = [
    "Elecciones presidenciales en Rep√∫blica Dominicana",
    "Resultados del juego de b√©isbol de anoche"
]
embeddings = model.encode(texts)

# Calcular similitud
from sentence_transformers.util import cos_sim
similarity = cos_sim(embeddings[0], embeddings[1])
print(f"Similitud: {similarity.item():.4f}")
```

## Troubleshooting

### Error: "No training examples generated"
- **Causa**: Corpus vac√≠o o sin categor√≠as
- **Soluci√≥n**: Ejecuta `uv run news export corpus` primero

### Error: "Database not found"
- **Causa**: No existe el archivo `ai/corpus/raw_news.db`
- **Soluci√≥n**: Ejecuta `uv run news export corpus`

### Advertencia: "Only X categories found"
- **Causa**: Pocas categor√≠as para entrenamiento efectivo
- **Soluci√≥n**: Exporta m√°s art√≠culos de diferentes fuentes/categor√≠as

### Error: "CUDA out of memory"
- **Causa**: Batch size muy grande para tu GPU
- **Soluci√≥n**: Reduce `batch_size` a 8 o 4

## Estructura de Archivos

```
ai/training/
‚îú‚îÄ‚îÄ README.md                    # Este archivo
‚îú‚îÄ‚îÄ analysis.py                  # An√°lisis del corpus
‚îú‚îÄ‚îÄ loaders/
‚îÇ   ‚îî‚îÄ‚îÄ category_loader.py       # Carga datos por categor√≠a
‚îî‚îÄ‚îÄ embeddings/
    ‚îú‚îÄ‚îÄ simple.py                # Entrenamiento jer√°rquico simple
    ‚îî‚îÄ‚îÄ controlled_ratios.py     # Entrenamiento balanceado

ai/corpus/
‚îî‚îÄ‚îÄ raw_news.db                  # Base de datos del corpus

ai/models/embeddings/
‚îî‚îÄ‚îÄ news-embeddings-*-TIMESTAMP/ # Modelos entrenados
```

## Workflow Completo

1. **Poblar base de datos principal**:
   ```bash
   uv run news article fetch-cached --limit 500
   ```

2. **Exportar corpus**:
   ```bash
   uv run news export corpus
   ```

3. **Analizar distribuci√≥n**:
   ```bash
   python ai/training/analysis.py
   ```

4. **Entrenar modelo**:
   ```bash
   python ai/training/embeddings/simple.py
   ```

5. **Usar modelo en tu aplicaci√≥n**:
   ```python
   from sentence_transformers import SentenceTransformer
   model = SentenceTransformer('ai/models/embeddings/news-embeddings-simple-20251120_141530')
   ```
