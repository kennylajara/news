# Sistema de Clasificaci√≥n de Entidades Asistido por IA

## Contexto

El sistema ya cuenta con:
1. **Clasificaci√≥n algor√≠tmica** (`auto-classify`) - Detecta patrones heur√≠sticos simples (iniciales, nombres parciales)
2. **Clasificaci√≥n manual** - El usuario revisa y clasifica entidades manualmente

## Problema a Resolver

La clasificaci√≥n algor√≠tmica tiene limitaciones:
- **No entiende contexto sem√°ntico**: "Luis" podr√≠a ser "Luis Abinader" o "Luis Rodolfo Abinader"
- **No detecta sin√≥nimos**: "Banco Central" vs "BCRD" (sin iniciales obvias)
- **Casos ambiguos complejos**: "Fern√°ndez" podr√≠a referirse a 5+ personas diferentes
- **Nombres con variaciones**: "Rep√∫blica Dominicana" vs "Rep. Dominicana" vs "RD"

**Resultado:** Miles de entidades quedan sin clasificar o mal clasificadas, requiriendo revisi√≥n manual costosa.

## Soluci√≥n Propuesta: Clasificaci√≥n Asistida por IA

Un proceso batch que usa **modelos de lenguaje (LLM)** para analizar contexto sem√°ntico y sugerir clasificaciones inteligentes.

---

## Ventajas del Enfoque con IA

### 1. **Comprensi√≥n de Contexto**

El LLM puede leer oraciones completas donde aparecen las entidades:

**Ejemplo:**
```
Entidad evaluada: "Luis"
Candidatos: "Luis Abinader", "Luis Rodolfo Abinader"

Contexto del art√≠culo:
"El presidente Luis anunci√≥ hoy..." ‚Üí "Luis Abinader"
"Luis Rodolfo asegur√≥ que..." ‚Üí "Luis Rodolfo Abinader"
```

### 2. **Detecci√≥n de Sin√≥nimos y Variaciones**

El LLM conoce formas comunes de referirse a entidades:

**Ejemplo:**
```
"BCRD" ‚Üí "Banco Central de la Rep√∫blica Dominicana"
"Banco Central" ‚Üí "Banco Central de la Rep√∫blica Dominicana"
"Central de RD" ‚Üí "Banco Central de la Rep√∫blica Dominicana"
```

### 3. **Manejo de Ambig√ºedad Compleja**

Cuando hay m√∫ltiples candidatos igualmente v√°lidos:

**Ejemplo:**
```
Entidad: "Mart√≠nez"
Contextos diferentes:
- "El ministro Mart√≠nez..." ‚Üí Pedro Mart√≠nez (Ministro de Obras P√∫blicas)
- "El diputado Mart√≠nez..." ‚Üí Jos√© Mart√≠nez (Diputado PRM)
- "Mart√≠nez, del equipo..." ‚Üí Juan Mart√≠nez (Jugador de b√©isbol)

Decisi√≥n: AMBIGUOUS con 3 canonicals
```

### 4. **Confianza Graduada**

El LLM puede expresar su nivel de certeza:

| Confianza | Acci√≥n Sugerida | Ejemplo |
|-----------|-----------------|---------|
| 90-100% | Auto-aprobar | "JCE" ‚Üí "Junta Central Electoral" (contexto claro) |
| 70-89% | Sugerir para revisi√≥n r√°pida | "Luis" ‚Üí "Luis Abinader" (probable pero verificar) |
| 50-69% | Revisi√≥n manual requerida | "Mart√≠nez" ‚Üí ambiguo entre 3 personas |
| <50% | Dejar sin clasificar | Insuficiente informaci√≥n |

---

## Arquitectura del Sistema

### Flujo General

```
1. Filtrar entidades no clasificadas
   ‚îî‚îÄ> last_review_type = 'none'
   ‚îî‚îÄ> Ordenar por: article_count DESC, name_length ASC

2. Por cada entidad (batch de 100):
   ‚îú‚îÄ> Buscar candidatos (reverse index)
   ‚îú‚îÄ> Obtener contexto de art√≠culos
   ‚îú‚îÄ> Preparar datos para LLM
   ‚îú‚îÄ> Llamar API de OpenAI
   ‚îú‚îÄ> Procesar respuesta estructurada
   ‚îú‚îÄ> Aplicar clasificaci√≥n seg√∫n confianza
   ‚îî‚îÄ> Marcar como last_review_type='ai-assisted'

3. Generar reporte de clasificaciones
   ‚îú‚îÄ> Auto-aprobadas (confianza alta)
   ‚îú‚îÄ> Sugerencias para revisi√≥n
   ‚îî‚îÄ> Sin clasificar (confianza baja)
```

### Componentes Clave

#### 1. Pre-filtrado con Reverse Index

Antes de llamar al LLM, usamos el **reverse index** (`entity_tokens`) para:
- Encontrar candidatos potenciales (solo entidades m√°s largas con tokens coincidentes)
- Reducir de miles de entidades a 5-10 candidatos por evaluada
- **Ahorrar costos** de API al no enviar todo al LLM

**Beneficio:** En lugar de enviar 1000 entidades al LLM, enviamos solo los 5 candidatos m√°s relevantes.

#### 2. Extracci√≥n de Contexto

Para cada entidad evaluada, se extrae:

| Dato | Fuente | Prop√≥sito |
|------|--------|-----------|
| **Menciones** | `article_entities.mentions` | Frecuencia de aparici√≥n |
| **Oraciones de contexto** | `article_entities.context_sentences` | C√≥mo se usa la entidad |
| **Art√≠culos compartidos** | `article_entities` JOIN | ¬øCandidato y evaluada aparecen juntos? |
| **Tipo detectado** | `named_entities.entity_type` | PERSON, ORG, GPE, etc. |
| **Relevancia** | `article_entities.relevance` | Importancia en el art√≠culo |

**Ejemplo de contexto extra√≠do:**
```json
{
  "entity_name": "Luis",
  "entity_type": "PERSON",
  "total_mentions": 45,
  "context_samples": [
    "El presidente Luis anunci√≥ hoy una nueva medida econ√≥mica",
    "Luis afirm√≥ que el gobierno continuar√° con las reformas"
  ],
  "candidates": [
    {
      "name": "Luis Abinader",
      "type": "PERSON",
      "shared_articles": 42,
      "context_overlap": "presidente, gobierno, reformas"
    },
    {
      "name": "Luis Rodolfo Abinader",
      "type": "PERSON",
      "shared_articles": 3,
      "context_overlap": "reformas"
    }
  ]
}
```

#### 3. Prompt Engineering

El sistema usa **templates Jinja2** para construir prompts estructurados:

**Sistema (`entity_classification_system_prompt.md.jinja`):**
```
Eres un experto en desambiguaci√≥n de entidades para un portal de noticias
dominicano. Tu tarea es analizar menciones de entidades y determinar si
deben clasificarse como:

- CANONICAL: Entidad principal (ya existe o es nueva)
- ALIAS: Variante de otra entidad (ej: "JCE" ‚Üí "Junta Central Electoral")
- AMBIGUOUS: Puede referirse a m√∫ltiples entidades (ej: "Mart√≠nez")
- NOT_AN_ENTITY: No es realmente una entidad (error de NER)

Considera:
- Contexto sem√°ntico de las oraciones
- Frecuencia de co-ocurrencia con candidatos
- Convenciones dominicanas (ej: "BCRD" = Banco Central)
- Coherencia con tipos detectados (PERSON, ORG, etc.)
```

**Usuario (`entity_classification_user_prompt.md.jinja`):**
```
Entidad a clasificar: {{ entity_name }}
Tipo detectado: {{ entity_type }}
Menciones totales: {{ total_mentions }}

Contexto de uso:
{% for sentence in context_samples %}
- {{ sentence }}
{% endfor %}

Candidatos encontrados:
{% for candidate in candidates %}
{{ loop.index }}. {{ candidate.name }} ({{ candidate.type }})
   - Art√≠culos compartidos: {{ candidate.shared_articles }}
   - Contexto: {{ candidate.context_overlap }}
{% endfor %}

¬øC√≥mo debe clasificarse "{{ entity_name }}"?
```

#### 4. Respuesta Estructurada (Pydantic)

El LLM devuelve una respuesta JSON validada:

**Schema (`src/llm/prompts/entity_classification.py`):**
```python
from pydantic import BaseModel, Field
from typing import Literal, Optional, List

class StructuredOutput(BaseModel):
    classification: Literal['canonical', 'alias', 'ambiguous', 'not_an_entity'] = Field(
        description="Clasificaci√≥n recomendada para la entidad"
    )

    canonical_ids: Optional[List[int]] = Field(
        default=None,
        description="IDs de entidades can√≥nicas (para ALIAS o AMBIGUOUS)"
    )

    confidence: float = Field(
        ge=0.0, le=1.0,
        description="Confianza de 0.0 a 1.0"
    )

    reasoning: str = Field(
        description="Explicaci√≥n breve de la decisi√≥n (1-2 frases)"
    )
```

**Ejemplo de respuesta:**
```json
{
  "classification": "alias",
  "canonical_ids": [123],
  "confidence": 0.92,
  "reasoning": "Contexto indica que 'Luis' se refiere al presidente Luis Abinader. Aparecen juntos en 42 de 45 art√≠culos con t√©rminos como 'presidente' y 'gobierno'."
}
```

---

## L√≥gica de Aplicaci√≥n de Clasificaciones

### Reglas de Auto-aprobaci√≥n

| Clasificaci√≥n | Confianza | Acci√≥n | `is_approved` |
|---------------|-----------|--------|---------------|
| `alias` | ‚â• 90% | Auto-aprobar | `1` ‚úÖ |
| `alias` | 70-89% | Aplicar pero no aprobar | `0` ‚ö†Ô∏è |
| `alias` | < 70% | No aplicar (manual) | - |
| `ambiguous` | ‚â• 80% | Auto-aprobar | `1` ‚úÖ |
| `ambiguous` | 50-79% | Aplicar pero no aprobar | `0` ‚ö†Ô∏è |
| `ambiguous` | < 50% | No aplicar (manual) | - |
| `canonical` | Cualquiera | Mantener como est√° | - |
| `not_an_entity` | ‚â• 85% | Auto-aprobar | `1` ‚úÖ |

### Marcado de Revisi√≥n

**Todas las entidades procesadas se marcan:**
```python
entity.last_review_type = 'ai-assisted'
entity.last_review = datetime.utcnow()
# is_approved seg√∫n tabla anterior
```

### Manejo de Conflictos

Si el algoritmo heur√≠stico ya clasific√≥ una entidad como `last_review_type='algorithmic'`:

**Regla:** El LLM puede **sobrescribir** si:
- Confianza del LLM ‚â• 85%
- Clasificaci√≥n del LLM difiere de la algor√≠tmica

**Ejemplo:**
```
Estado actual:
- Entidad: "BC"
- classified_as: ALIAS ‚Üí "Banco Central"
- last_review_type: 'algorithmic'
- is_approved: 1

LLM sugiere:
- classification: 'ambiguous'
- canonical_ids: [45, 67]  # "Banco Central" y "Barcelona FC"
- confidence: 0.88

Acci√≥n:
- Convertir a AMBIGUOUS
- Actualizar canonical_refs
- last_review_type = 'ai-assisted'
- is_approved = 0  (requiere confirmaci√≥n humana por cambio)
```

---

## Integraci√≥n con Sistema Existente

### Reutilizaci√≥n de Componentes

| Componente | Origen | Uso en IA-Assisted |
|------------|--------|-------------------|
| `entity_tokens` | Auto-classification | Pre-filtrado de candidatos |
| `openai_structured_output()` | Flash News generation | Llamada gen√©rica a LLM |
| Prompt templates (Jinja2) | Core clustering | Sistema de prompts |
| `set_as_alias()` / `set_as_ambiguous()` | Entity models | Aplicar clasificaciones |
| Batch processing | Article enrichment | Procesar en lotes con logs |
| Cascade updates | Auto-classification | Actualizar dependientes |

### Nueva Tabla: `entity_classification_suggestions`

Para auditor√≠a y revisi√≥n manual posterior:

| Campo | Tipo | Descripci√≥n |
|-------|------|-------------|
| `id` | INTEGER | ID √∫nico |
| `entity_id` | INTEGER | Entidad evaluada |
| `suggested_classification` | VARCHAR(20) | 'alias', 'ambiguous', 'not_an_entity' |
| `suggested_canonical_ids` | JSON | IDs sugeridos (array) |
| `confidence` | FLOAT | 0.0 - 1.0 |
| `reasoning` | TEXT | Explicaci√≥n del LLM |
| `applied` | INTEGER | 0 = sugerencia, 1 = aplicada |
| `approved_by_user` | INTEGER | NULL, 0 = rechazada, 1 = aprobada |
| `created_at` | DATETIME | Timestamp |

**Prop√≥sito:**
- Auditar todas las sugerencias del LLM
- Permitir revisi√≥n manual de sugerencias de baja confianza
- Mejorar el sistema con feedback humano

---

## Workflow de Uso

### 1. Ejecutar Clasificaci√≥n IA

```bash
# Clasificar entidades sin revisar (dry-run)
uv run news entity ai-classify --dry-run

# Aplicar clasificaciones con confianza alta (‚â•90%)
uv run news entity ai-classify --min-confidence 0.90

# Aplicar todas las sugerencias (‚â•70%)
uv run news entity ai-classify --min-confidence 0.70

# Procesar solo un tipo de entidad
uv run news entity ai-classify --type person --min-confidence 0.85

# Limitar cantidad de entidades a procesar
uv run news entity ai-classify --limit 100
```

### 2. Revisar Sugerencias de Baja Confianza

```bash
# Ver sugerencias no aplicadas (confianza < umbral)
uv run news entity suggestions list --not-applied

# Ver sugerencias aplicadas pero no aprobadas
uv run news entity suggestions list --pending-approval

# Aprobar una sugerencia espec√≠fica
uv run news entity suggestions approve <suggestion_id>

# Rechazar una sugerencia
uv run news entity suggestions reject <suggestion_id>
```

### 3. Generar Reportes

```bash
# Reporte de clasificaciones del √∫ltimo batch
uv run news entity ai-classify --report

# Estad√≠sticas de accuracy
uv run news entity suggestions stats
```

**Salida esperada:**
```
üìä Reporte de Clasificaci√≥n Asistida por IA

Entidades procesadas: 250
‚îú‚îÄ Auto-aprobadas (confianza ‚â•90%): 180 (72%)
‚îÇ  ‚îú‚îÄ ALIAS: 120
‚îÇ  ‚îú‚îÄ AMBIGUOUS: 50
‚îÇ  ‚îî‚îÄ NOT_AN_ENTITY: 10
‚îú‚îÄ Aplicadas sin aprobar (70-89%): 45 (18%)
‚îî‚îÄ Sugeridas para revisi√≥n manual (<70%): 25 (10%)

Tiempo promedio por entidad: 2.3 segundos
Costo estimado (API): $0.08
```

---

## Consideraciones T√©cnicas

### 1. Costos de API

**Estimaci√≥n por entidad:**
- Tokens de entrada: ~500-800 (contexto + candidatos)
- Tokens de salida: ~100-150 (respuesta estructurada)
- Costo por entidad: **$0.0003 - $0.0005** (con GPT-5-nano)

**Para 10,000 entidades:** $3 - $5 USD

**Optimizaciones:**
- Pre-filtrar con reverse index (reduce candidatos enviados)
- Procesar en batch (compartir contexto com√∫n)
- Usar modelo m√°s econ√≥mico para casos simples (GPT-5-nano)
- Cachear resultados de entidades similares

### 2. Velocidad de Procesamiento

| Paso | Tiempo | Cuello de botella |
|------|--------|-------------------|
| Filtrado de candidatos | <1ms | Reverse index (indexado) |
| Extracci√≥n de contexto | 10-50ms | Queries SQL |
| Llamada a LLM | 1-3s | API de OpenAI |
| Aplicaci√≥n de clasificaci√≥n | <10ms | Updates SQL |
| **Total por entidad** | **~2-4s** | **LLM API** |

**Paralelizaci√≥n:**
- Procesar 10 entidades en paralelo ‚Üí 10,000 entidades en ~30-60 minutos

### 3. Manejo de Errores

**Estrategia resiliente:**

```python
def classify_entity_with_ai(entity, session):
    try:
        # 1. Pre-filtrado
        candidates = find_candidates_via_index(entity)

        # 2. Extraer contexto
        context = extract_entity_context(entity, candidates, session)

        # 3. Llamar LLM con retry
        result = openai_structured_output(
            'entity_classification',
            context,
            max_retries=3
        )

        # 4. Validar respuesta
        if result.confidence < MIN_CONFIDENCE:
            log_suggestion(entity, result, applied=False)
            return ('skipped', 'low_confidence')

        # 5. Aplicar clasificaci√≥n
        apply_classification(entity, result, session)
        log_suggestion(entity, result, applied=True)

        return ('success', result.classification)

    except OpenAIError as e:
        log_error(entity, e)
        return ('error', 'api_failure')

    except Exception as e:
        log_error(entity, e)
        return ('error', 'unexpected')
```

**Ventajas:**
- Un error no detiene el batch completo
- Logs detallados por entidad
- Retry autom√°tico de llamadas fallidas
- Sugerencias guardadas incluso si no se aplican

---

## Mejora Continua

### Feedback Loop

El sistema aprende de correcciones humanas:

**Proceso:**
1. Usuario revisa sugerencias de IA
2. Aprueba o rechaza v√≠a comando CLI
3. Sistema registra feedback en `entity_classification_suggestions.approved_by_user`
4. **Futuro:** Reentrenar o ajustar prompts seg√∫n feedback

**M√©tricas de Accuracy:**
```sql
-- Precisi√≥n del sistema
SELECT
  suggested_classification,
  COUNT(*) as total,
  SUM(CASE WHEN approved_by_user = 1 THEN 1 ELSE 0 END) as approved,
  ROUND(AVG(confidence), 2) as avg_confidence
FROM entity_classification_suggestions
WHERE applied = 1
GROUP BY suggested_classification;
```

**Output esperado:**
```
classification | total | approved | avg_confidence
---------------|-------|----------|---------------
alias          | 450   | 425      | 0.89
ambiguous      | 180   | 165      | 0.78
not_an_entity  | 35    | 32       | 0.91
```

### Ajuste de Umbrales

Seg√∫n resultados de producci√≥n, ajustar:

| Par√°metro | Actual | Ajuste Posible |
|-----------|--------|----------------|
| `MIN_CONFIDENCE_AUTO_APPROVE` | 0.90 | 0.85 si accuracy >95% |
| `MIN_CONFIDENCE_APPLY` | 0.70 | 0.75 si muchos falsos positivos |
| `MAX_CANDIDATES_TO_LLM` | 5 | 10 si se pierden matches |

---

## Comparaci√≥n: Algoritmo vs IA

| Aspecto | Clasificaci√≥n Algor√≠tmica | Clasificaci√≥n con IA |
|---------|---------------------------|----------------------|
| **Velocidad** | Instant√°nea (~1ms) | 2-4 segundos por entidad |
| **Costo** | $0 | ~$0.0004 por entidad |
| **Precisi√≥n** | 75-85% (casos simples) | 90-95% (casos complejos) |
| **Casos soportados** | Iniciales, nombres parciales | Sin√≥nimos, contexto, ambig√ºedad |
| **Explainability** | Reglas fijas | Razonamiento del LLM |
| **Escalabilidad** | Miles/minuto | Cientos/minuto |
| **Mejor para** | Casos obvios (JCE ‚Üí Junta) | Casos ambiguos (Luis ‚Üí ¬øqui√©n?) |

**Estrategia recomendada:**
1. Ejecutar clasificaci√≥n algor√≠tmica primero (r√°pida y gratuita)
2. Usar IA para entidades que quedaron sin clasificar o con baja confianza
3. Revisi√≥n manual para casos extremadamente ambiguos

---

## Pr√≥ximos Pasos

### Fase 1: Implementaci√≥n Base ‚úÖ (Planeada)
- [x] Dise√±o de arquitectura
- [ ] Implementar `entity_classification.py` (processor)
- [ ] Crear prompts (system + user)
- [ ] Schema Pydantic para respuesta estructurada
- [ ] Comando CLI `entity ai-classify`

### Fase 2: Optimizaciones
- [ ] Batch processing con paralelizaci√≥n
- [ ] Sistema de sugerencias (`entity_classification_suggestions`)
- [ ] Comando de revisi√≥n (`entity suggestions`)
- [ ] M√©tricas y reportes

### Fase 3: Mejora Continua
- [ ] Feedback loop (aprender de correcciones)
- [ ] A/B testing de prompts
- [ ] Fine-tuning de umbrales de confianza
- [ ] Integraci√≥n con UI web para revisi√≥n

---

## Conclusi√≥n

La clasificaci√≥n asistida por IA complementa el sistema algor√≠tmico existente, permitiendo:
- **Mayor precisi√≥n** en casos ambiguos
- **Comprensi√≥n sem√°ntica** del contexto
- **Reducci√≥n de trabajo manual** del 60-80%
- **Auditor√≠a completa** de decisiones

El sistema est√° dise√±ado para ser:
- **Eficiente**: Pre-filtrado con reverse index
- **Econ√≥mico**: ~$0.0004 por entidad
- **Seguro**: Sugerencias auditadas + umbrales de confianza
- **Escalable**: Procesamiento en batch + paralelizaci√≥n
