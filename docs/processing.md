# Procesamiento de Art√≠culos

## Introducci√≥n

El sistema de procesamiento por lotes permite ejecutar diferentes tipos de procesamiento sobre art√≠culos de forma eficiente y trazable.

## Tipos de Procesamiento

### Enriquecimiento de Art√≠culos (`enrich_article`)

Proceso base que realiza clustering sem√°ntico de oraciones. La extracci√≥n de entidades se hace en `analyze_article` con OpenAI.

**Caracter√≠sticas**:
- **Clustering sem√°ntico** de oraciones con clasificaci√≥n (core, secondary, filler)
- Genera embeddings con `paraphrase-multilingual-MiniLM-L12-v2`
- Clustering con UMAP + HDBSCAN
- Guarda en `article_clusters` y `article_sentences`
- Marca art√≠culo como `cluster_enriched_at` y `enriched_at`
- Guarda logs detallados del procesamiento
- **Performance**: ~2-3 segundos por art√≠culo

### An√°lisis Profundo de Art√≠culos (`analyze_article`)

Proceso de an√°lisis avanzado con OpenAI que extrae entidades nombradas y genera an√°lisis detallado para el sistema de recomendaciones. **Requiere que los art√≠culos ya est√©n enriquecidos** (con clustering completado).

**Caracter√≠sticas**:
- **Extracci√≥n de entidades con OpenAI**: Personas, organizaciones, ubicaciones, eventos, productos, NORP
- **An√°lisis profundo para recomendaciones**: Conceptos clave, relaciones sem√°nticas, marcos narrativos
- **Structured Outputs**: Usa esquema Pydantic para garantizar formato consistente
- **Dos tablas generadas**:
  - `article_entities`: Entidades extra√≠das con menciones y relevancia
  - `article_analyses`: An√°lisis completo del art√≠culo (tono, formato, audiencia, calidad, etc.)
- **Idempotente**: Detecta y salta art√≠culos que ya tienen an√°lisis
- **Manejo robusto de errores**: Fallas individuales no afectan otros art√≠culos
- **Performance**: ~5-10 segundos por art√≠culo (seg√∫n modelo de OpenAI)

**Campos generados en `article_analyses`**:
- **Sem√°ntica**: `key_concepts`, `semantic_relations`
- **Narrativa**: `narrative_frames`, `editorial_tone`, `style_descriptors`
- **Controversia y sesgo**: `controversy_score` (0-100), `political_bias` (-100 a 100)
- **Calidad**: `quality_score` (0-100), `has_named_sources`, `has_data_or_statistics`, `has_multiple_perspectives`
- **Formato**: `content_format` (news/feature/opinion/analysis/interview/listicle), `temporal_relevance` (breaking/timely/evergreen)
- **Audiencia**: `audience_education`, `target_age_range`, `target_professions`, `required_interests`
- **Industria y geograf√≠a**: `relevant_industries`, `geographic_scope`, `cultural_context`
- **Diversidad**: `voices_represented`, `source_diversity_score` (0-100)

**Uso en sistema de recomendaciones**: Permite matching avanzado basado en:
- Tono editorial (neutral, cr√≠tico, celebratorio, etc.)
- Formato de contenido (noticias vs. an√°lisis vs. opini√≥n)
- Nivel educativo de la audiencia
- Industrias relevantes
- Calidad y sesgo pol√≠tico

### Generaci√≥n de Flash News (`generate_flash_news`)

Proceso independiente que genera res√∫menes narrativos desde clusters importantes usando OpenAI. **Requiere que los art√≠culos ya est√©n enriquecidos** (con clustering completado).

**L√≥gica de selecci√≥n de clusters**:
1. **Preferencia**: Clusters CORE (score >= 0.60, no ruido)
2. **Fallback**: Si no hay CORE, acepta clusters SECONDARY con score > 0.60 (incluyendo clusters de ruido con alta puntuaci√≥n)

**Caracter√≠sticas**:
- **Generaci√≥n con LLM**: Usa OpenAI Structured Outputs (GPT-4/5)
- **Embeddings autom√°ticos** para res√∫menes y b√∫squeda sem√°ntica
- **Idempotente**: Detecta y salta clusters que ya tienen flash news
- **Manejo robusto de errores**: Fallas individuales no afectan otros clusters
- **Stats detalladas**: core_clusters_found, high_score_secondary_clusters_found, flash_news_generated, flash_news_skipped
- **Performance**: ~10-15 segundos por cluster (seg√∫n modelo de OpenAI)

**Nota**: Algunos art√≠culos pueden tener un solo cluster sem√°ntico cohesivo que el algoritmo marca como "ruido" (label=-1) pero con score muy alto. El sistema ahora los aprovecha para generar flash news cuando no hay alternativas CORE.

## Comandos CLI

### Iniciar Procesamiento

Crea y ejecuta un batch de procesamiento para art√≠culos de un dominio.

```bash
uv run news process start -d <dominio> -t <tipo> -s <tama√±o>
```

**Par√°metros**:
- `-d, --domain`: Dominio a procesar (requerido)
- `-t, --type`: Tipo de procesamiento (requerido)
  - `enrich_article`: Clustering sem√°ntico de oraciones (sin OpenAI)
  - `analyze_article`: Extracci√≥n de entidades + an√°lisis profundo (con OpenAI)
  - `generate_flash_news`: Generaci√≥n de flash news con LLM (con OpenAI)
- `-s, --size`: Tama√±o del batch (default: 10)

**Ejemplos**:
```bash
# Paso 1: Enriquecimiento base (clustering sem√°ntico)
uv run news process start -d diariolibre.com -t enrich_article -s 10

# Paso 2: An√°lisis profundo con OpenAI (extracci√≥n de entidades + an√°lisis)
uv run news process start -d diariolibre.com -t analyze_article -s 10

# Paso 3: Generaci√≥n de flash news (OpenAI)
uv run news process start -d diariolibre.com -t generate_flash_news -s 10
```

### Listar Batches

Muestra todos los batches de procesamiento con opciones de filtrado.

```bash
uv run news process list [opciones]
```

**Par√°metros opcionales**:
- `-l, --limit`: N√∫mero de batches a mostrar (default: 20)
- `-s, --status`: Filtrar por estado (pending, processing, completed, failed)
- `-d, --domain`: Filtrar por dominio

**Ejemplos**:
```bash
# Listar √∫ltimos 20 batches
uv run news process list

# Listar batches completados
uv run news process list --status completed

# Listar batches de un dominio
uv run news process list --domain diariolibre.com

# Combinar filtros
uv run news process list --domain diariolibre.com --status failed --limit 10
```

### Ver Detalles de Batch

Muestra informaci√≥n detallada sobre un batch espec√≠fico.

```bash
uv run news process show <batch_id> [--item <item_id>]
```

**Ejemplos**:
```bash
# Ver resumen del batch
uv run news process show 1

# Ver logs detallados de un item espec√≠fico
uv run news process show 1 --item 5
```

**Informaci√≥n mostrada**:
- Metadatos del batch (source, tipo, estado)
- Progreso (total, procesados, exitosos, fallidos)
- Estad√≠sticas agregadas
- Tiempos de ejecuci√≥n y duraci√≥n
- Resumen de items por estado
- Primeros 5 items fallidos (si hay)

## Flujo de Procesamiento

### Proceso: `enrich_article`

1. **Selecci√≥n de art√≠culos**: Art√≠culos con `enriched_at IS NULL`
2. **Creaci√≥n de batch y items**: Transacci√≥n at√≥mica en `processing_batches` y `batch_items`
3. **Procesamiento por art√≠culo**:

   **FASE 1: Clustering Sem√°ntico**
   - Extrae oraciones del contenido (excluye headers markdown)
   - Genera embeddings con `paraphrase-multilingual-MiniLM-L12-v2`
   - Clustering con UMAP + HDBSCAN
   - Clasifica clusters en: core (‚â•0.60), secondary (0.30-0.60), filler (<0.30)
   - Guarda en `article_clusters` y `article_sentences`
   - Marca art√≠culo como `cluster_enriched_at`

   **FASE 2: Finalizaci√≥n**
   - Marca art√≠culo como enriquecido (`enriched_at`)
   - Actualiza batch item con logs y estad√≠sticas
   - Commit a base de datos

4. **Finalizaci√≥n del batch**: Actualiza estad√≠sticas agregadas

### Proceso: `generate_flash_news`

1. **Selecci√≥n de art√≠culos**: Art√≠culos con `cluster_enriched_at IS NOT NULL` (ya tienen clusters)
2. **Creaci√≥n de batch y items**: Transacci√≥n at√≥mica
3. **Procesamiento por art√≠culo**:

   **FASE 1: Obtenci√≥n de Clusters CORE**
   - Query a `article_clusters` filtrando por `category = 'CORE'`
   - Si no hay clusters core, marca item como completado y contin√∫a

   **FASE 2: Generaci√≥n de Flash News por Cluster**
   - Para cada cluster core:
     - **Verificaci√≥n de idempotencia**: Salta si ya existe flash news para ese cluster
     - **Obtenci√≥n de oraciones**: Query a `article_sentences` ordenadas por √≠ndice
     - **Preparaci√≥n de datos**: Diccionario con t√≠tulo, oraciones del cluster, score
     - **Llamada a LLM**:
       - Renderiza prompts Jinja2 (system + user)
       - Llama OpenAI API con Structured Outputs
       - Recibe resumen JSON (validado con Pydantic)
     - **Generaci√≥n de embedding**: Embedding del resumen con mismo modelo que clustering
     - **Guardado**: Crea registro `FlashNews` (published=0)
   - **Manejo de errores**: Fallas en un cluster no afectan otros

   **FASE 3: Finalizaci√≥n**
   - Actualiza batch item con estad√≠sticas:
     - `core_clusters_found`
     - `flash_news_generated`
     - `flash_news_skipped`
   - Commit a base de datos

4. **Finalizaci√≥n del batch**: Actualiza estad√≠sticas agregadas

### Proceso: `analyze_article`

Genera an√°lisis profundo de art√≠culos usando OpenAI para extracci√≥n de entidades y an√°lisis multi-dimensional.

**Prerrequisitos**: Art√≠culos que NO tengan registro en `article_analyses` (evita re-an√°lisis innecesario)

**Proceso**:

1. **Selecci√≥n de art√≠culos**: LEFT JOIN con `article_analyses WHERE article_analyses.id IS NULL`
2. **Creaci√≥n de batch y items**: Transacci√≥n at√≥mica
3. **Procesamiento por art√≠culo**:

   **FASE 1: Extracci√≥n de Entidades con OpenAI**
   - Llama OpenAI API con art√≠culo completo (t√≠tulo, subt√≠tulo, contenido, fecha, categor√≠a)
   - Extrae entidades de **6 tipos**:
     - PERSON (personas)
     - ORG (organizaciones, compa√±√≠as, instituciones)
     - GPE (pa√≠ses, ciudades, estados)
     - EVENT (eventos, huracanes, batallas, etc.)
     - PRODUCT (productos, servicios)
     - NORP (nacionalidades, grupos religiosos/pol√≠ticos)
   - Cuenta menciones por entidad
   - **Auto-aprueba** todas las entidades: `is_approved=1`, `last_review_type='ai-assisted'`
   - Guarda en `named_entities` (permite mismo nombre con diferentes tipos)
   - Guarda relaci√≥n art√≠culo-entidad en `article_entities` con:
     - `mentions`: N√∫mero de menciones en el art√≠culo
     - `relevance`: Calculada como `min(mentions / 10.0, 1.0)`
     - `origin`: `AI_ANALYSIS`

   **FASE 2: An√°lisis Multi-dimensional**
   - Extrae 13 factores de an√°lisis del art√≠culo:
     - **Sem√°ntica**: Conceptos clave
     - **Narrativa**: Frames narrativos, tono editorial
     - **Controversia/sesgo**: Puntaje de controversia, sesgo pol√≠tico
     - **Formato**: Tipo de contenido (noticia, opini√≥n, an√°lisis, etc.)
     - **Temporal**: Relevancia temporal (breaking, recent, timeless, etc.)
     - **Audiencia**: Nivel educativo, rango de edad
     - **Industria**: Industrias relevantes
     - **Geogr√°fico**: Alcance geogr√°fico
   - Guarda en `article_analysis` (tabla separada con FK a article_id)

   **FASE 3: Finalizaci√≥n**
   - Actualiza batch item con logs y estad√≠sticas
   - Commit a base de datos

4. **Finalizaci√≥n del batch**: Actualiza estad√≠sticas agregadas

**Performance**: ~10-15 segundos por art√≠culo (depende de latencia OpenAI)

## Entidades Extra√≠das

El sistema extrae entidades usando **OpenAI** durante el proceso `analyze_article`:

### Extracci√≥n con OpenAI (`analyze_article`)

Extrae **6 tipos** de entidades con an√°lisis sem√°ntico profundo:

| Tipo | Descripci√≥n |
|------|-------------|
| PERSON | Personas, incluyendo ficticias |
| ORG | Compa√±√≠as, agencias, instituciones |
| GPE | Pa√≠ses, ciudades, estados |
| EVENT | Huracanes, batallas, guerras, eventos deportivos |
| PRODUCT | Objetos, veh√≠culos, alimentos, servicios |
| NORP | Nacionalidades, grupos religiosos o pol√≠ticos |

- **EntityOrigin**: `AI_ANALYSIS`
- **Auto-aprobaci√≥n**: Todas las entidades se crean con `is_approved=1`, `last_review_type='ai-assisted'`

## Campos de Seguimiento

### ProcessingBatch

- `status`: pending, processing, completed, failed
- `total_items`: Total de art√≠culos en el batch
- `processed_items`: Art√≠culos procesados (exitosos + fallidos)
- `successful_items`: Art√≠culos exitosos
- `failed_items`: Art√≠culos fallidos
- `stats` (JSON): Estad√≠sticas agregadas del batch
- `started_at`, `completed_at`: Timestamps de ejecuci√≥n

### BatchItem

- `status`: pending, processing, completed, failed, skipped
- `logs` (TEXT): Logs detallados del procesamiento
- `stats` (JSON): Estad√≠sticas del item individual
  - `entities_found`: Total de entidades encontradas
  - `entities_new`: Entidades nuevas creadas
  - `entities_existing`: Entidades existentes actualizadas
  - `processing_time`: Tiempo de procesamiento en segundos
- `error_message`: Mensaje de error si fall√≥
- `started_at`, `completed_at`: Timestamps

## M√©tricas de Entidades

El sistema maneja dos niveles de m√©tricas:

### Contador Global de Art√≠culos (`named_entities.article_count`)

Campo INTEGER que cuenta en cu√°ntos art√≠culos aparece la entidad:
- Primera vez que se menciona (en cualquier art√≠culo): `article_count = 1`
- Segunda vez (en otro art√≠culo): `article_count = 2`
- Y as√≠ sucesivamente

Esto permite identificar las entidades m√°s frecuentes del corpus completo.

### Menciones por Art√≠culo (`article_entities.mentions`)

Campo INTEGER que cuenta cu√°ntas veces aparece la entidad en un art√≠culo espec√≠fico.

**Ejemplo**:
- "Polic√≠a" aparece 3 veces en art√≠culo A ‚Üí `mentions = 3`
- "Polic√≠a" aparece 2 veces en art√≠culo B ‚Üí `mentions = 2`
- Resultado: `article_count = 2` (2 art√≠culos)

## C√°lculo de Relevancia

La relevancia (`article_entities.relevance`) es un score FLOAT que indica la importancia de una entidad dentro de un art√≠culo espec√≠fico.

### F√≥rmula

**Base Score** (en base 1):
```
base_score = menciones_de_esta_entidad / total_menciones_de_todas_las_entidades
```

**Ejemplo**:
- Art√≠culo menciona: Alice (2), Bob (1), Charlie (1)
- Total menciones = 4
- Alice base_score = 2/4 = 0.5
- Bob base_score = 1/4 = 0.25
- Charlie base_score = 1/4 = 0.25

**Bonos** (sumados como porcentajes del base_score):

| Condici√≥n | Bono | F√≥rmula |
|-----------|------|---------|
| Aparece en t√≠tulo | +50% del base_score | `score += base_score * 0.5` |
| Aparece en subt√≠tulo | +25% del base_score | `score += base_score * 0.25` |
| Primera menci√≥n en primer 20% del contenido | +30% del base_score | `score += base_score * 0.3` |
| Primera menci√≥n en primer 40% del contenido | +15% del base_score | `score += base_score * 0.15` |
| M√°s de 3 menciones | +10% del base_score por menci√≥n extra (cap +50%) | `score += base_score * (min(menciones-3, 5) * 0.1)` |

**Normalizaci√≥n**:
Despu√©s de calcular todos los scores, se normalizan para que la entidad m√°s relevante del art√≠culo tenga un score de 1.0:
```
normalization_factor = 1.0 / max_relevance
normalized_score = raw_score * normalization_factor
```

**Ejemplo completo**:
```
Art√≠culo con: Alice (2 menciones), Bob (1), Charlie (1)
Total menciones = 4

Alice:
- base_score = 2/4 = 0.5
- Aparece en t√≠tulo ‚Üí 0.5 + (0.5 * 0.5) = 0.75
- Primera menci√≥n en primer 20% ‚Üí 0.75 + (0.5 * 0.3) = 0.9
- raw_score = 0.9

Bob:
- base_score = 1/4 = 0.25
- raw_score = 0.25

Charlie:
- base_score = 1/4 = 0.25
- raw_score = 0.25

Normalizaci√≥n (max = 0.9):
- Alice: 0.9 * (1.0/0.9) = 1.0
- Bob: 0.25 * (1.0/0.9) = 0.278
- Charlie: 0.25 * (1.0/0.9) = 0.278
```

## Acceso a Informaci√≥n

### A trav√©s de la CLI

La mayor√≠a de consultas comunes est√°n disponibles a trav√©s de comandos CLI. Ver [Referencia de Comandos](commands.md) para la documentaci√≥n completa.

**Ejemplos:**
- Ver batches: `uv run news process list`
- Ver detalles de batch: `uv run news process show <batch_id>`
- Ver logs de item: `uv run news process show <batch_id> --item <item_id>`
- Ver flash news: `uv run news flash list`
- Ver detalles de flash news: `uv run news flash show <id>`
- Ver estad√≠sticas de flash news: `uv run news flash stats`
- Ver entidades m√°s relevantes: `uv run news entity list`
- Ver art√≠culos enriquecidos: `uv run news article list --enriched`
- Ver art√≠culos pendientes: `uv run news article list --pending-enrich`
- Ver entidades de art√≠culo: `uv run news article show <id> --entities`
- Ver art√≠culos que mencionan entidad: `uv run news entity show "<nombre>"`
- Ver estad√≠sticas: `uv run news domain stats`

### Consultas SQL Avanzadas

Para an√°lisis avanzados, puedes acceder directamente a la base de datos:

```bash
sqlite3 data/news.db
```

**Tendencias temporales de entidades**:
```sql
SELECT
    ne.name,
    ne.entity_type,
    DATE(a.published_date) as date,
    COUNT(*) as mentions_count,
    SUM(ae.mentions) as total_mentions
FROM article_entities ae
JOIN named_entities ne ON ae.entity_id = ne.id
JOIN articles a ON ae.article_id = a.id
WHERE a.published_date IS NOT NULL
GROUP BY ne.id, DATE(a.published_date)
ORDER BY date DESC, mentions_count DESC;
```

**Co-ocurrencia de entidades** (entidades que aparecen juntas):
```sql
SELECT
    ne1.name as entity1,
    ne2.name as entity2,
    COUNT(*) as co_occurrences
FROM article_entities ae1
JOIN article_entities ae2 ON ae1.article_id = ae2.article_id AND ae1.entity_id < ae2.entity_id
JOIN named_entities ne1 ON ae1.entity_id = ne1.id
JOIN named_entities ne2 ON ae2.entity_id = ne2.id
GROUP BY ae1.entity_id, ae2.entity_id
ORDER BY co_occurrences DESC
LIMIT 20;
```

**Entidades por tipo de art√≠culo** (categor√≠a):
```sql
SELECT
    a.category,
    ne.entity_type,
    COUNT(DISTINCT ne.id) as unique_entities,
    SUM(ae.mentions) as total_mentions
FROM articles a
JOIN article_entities ae ON a.id = ae.article_id
JOIN named_entities ne ON ae.entity_id = ne.id
WHERE a.category IS NOT NULL
GROUP BY a.category, ne.entity_type
ORDER BY a.category, total_mentions DESC;
```

**Performance de procesamiento por batch**:
```sql
SELECT
    pb.id,
    pb.source_id,
    s.domain,
    pb.total_items,
    pb.successful_items,
    pb.failed_items,
    (pb.successful_items * 100.0 / pb.total_items) as success_rate,
    (JULIANDAY(pb.completed_at) - JULIANDAY(pb.started_at)) * 86400 as duration_seconds,
    ((JULIANDAY(pb.completed_at) - JULIANDAY(pb.started_at)) * 86400) / pb.total_items as avg_seconds_per_item
FROM processing_batches pb
JOIN sources s ON pb.source_id = s.id
WHERE pb.completed_at IS NOT NULL
ORDER BY pb.created_at DESC;
```

## Flash News

### Descripci√≥n

Flash news son res√∫menes narrativos concisos generados autom√°ticamente desde los clusters sem√°nticos identificados como "core" (n√∫cleo) de los art√≠culos. Cada flash news:

- Resume las ideas principales de un cluster core (2-3 oraciones)
- Es autocontenida y comprensible sin contexto adicional
- Usa tono period√≠stico profesional en espa√±ol
- Incluye un embedding vectorial para b√∫squeda sem√°ntica
- Tiene estado publicado/no publicado

### Generaci√≥n Autom√°tica

El proceso de generaci√≥n usa **OpenAI Structured Outputs** con:

1. **Templates Jinja2 separados**:
   - `{task}_system_prompt.md.jinja` - Instrucciones para el LLM
   - `{task}_user_prompt.md.jinja` - Datos espec√≠ficos del cluster

2. **Schema Pydantic** (`{task}.py`):
   - Valida la respuesta del LLM
   - Garantiza formato JSON correcto

3. **Wrapper gen√©rico reutilizable** (`src/llm/openai_client.py`):
   - Funci√≥n `openai_structured_output(task_name, data)`
   - Carga din√°micamente templates y schemas
   - Renderiza prompts con datos del cluster
   - Llama OpenAI API con validaci√≥n estricta

### Configuraci√≥n Requerida

Para usar la generaci√≥n de flash news, necesitas configurar OpenAI API.

Ver **[README.md](../README.md)** secci√≥n "Instalaci√≥n" para instrucciones completas de configuraci√≥n de variables de entorno (`.env` file).

### Consultas SQL para Flash News

**Listar flash news no publicadas**:
```sql
SELECT
    fn.id,
    fn.summary,
    a.title as article_title,
    ac.score as cluster_score,
    fn.created_at
FROM flash_news fn
JOIN article_clusters ac ON fn.cluster_id = ac.id
JOIN articles a ON ac.article_id = a.id
WHERE fn.published = 0
ORDER BY fn.created_at DESC;
```

**Estad√≠sticas de flash news por fuente**:
```sql
SELECT
    s.domain,
    COUNT(fn.id) as total_flash_news,
    SUM(fn.published) as published,
    COUNT(fn.id) - SUM(fn.published) as unpublished
FROM flash_news fn
JOIN article_clusters ac ON fn.cluster_id = ac.id
JOIN articles a ON ac.article_id = a.id
JOIN sources s ON a.source_id = s.id
GROUP BY s.domain
ORDER BY total_flash_news DESC;
```

**Flash news con embeddings para b√∫squeda**:
```sql
SELECT
    fn.id,
    fn.summary,
    LENGTH(fn.embedding) as embedding_size,
    a.title
FROM flash_news fn
JOIN article_clusters ac ON fn.cluster_id = ac.id
JOIN articles a ON ac.article_id = a.id
WHERE fn.embedding IS NOT NULL;
```

### Crear Nuevas Tareas LLM

Para agregar una nueva tarea de procesamiento con LLM:

1. **Crear schema Pydantic** (`src/llm/prompts/{task}.py`):
```python
from pydantic import BaseModel, Field

class StructuredOutput(BaseModel):
    campo1: str = Field(description="Descripci√≥n del campo")
    campo2: list[str] = Field(description="...")
```

2. **Crear prompt del sistema** (`src/llm/prompts/{task}_system_prompt.md.jinja`):
```jinja
Eres un experto en...

Directrices:
- Instrucci√≥n 1
- Instrucci√≥n 2
```

3. **Crear prompt del usuario** (`src/llm/prompts/{task}_user_prompt.md.jinja`):
```jinja
**Datos de entrada:**
{{ variable1 }}
{{ variable2 }}

Genera...
```

4. **Usar en c√≥digo**:
```python
from llm.openai_client import openai_structured_output

data = {'variable1': 'valor', 'variable2': 'otro valor'}
result = openai_structured_output('nombre_de_tarea', data)
print(result.campo1)
```

---

## Sistema de Desambiguaci√≥n de Entidades

### Introducci√≥n

El sistema de desambiguaci√≥n resuelve el problema de entidades ambiguas extra√≠das por OpenAI, donde el mismo texto puede referirse a m√∫ltiples personas/organizaciones diferentes. Por ejemplo:
- **"Luis"** puede ser ‚Üí Luis Abinader (presidente) o Luis Fonsi (cantante)
- **"PRM"** puede ser ‚Üí Partido Revolucionario Moderno o Performance Rights Management

### Clasificaciones de Entidades

Cada entidad en `named_entities` tiene un campo `classified_as` con uno de estos valores:

#### 1. **CANONICAL** (default)
Entidad principal o "verdadera".

**Caracter√≠sticas**:
- Es la entidad de referencia
- No puede tener `canonical_refs` salientes (pero puede recibir referencias de otras entidades)
- Acumula la relevancia de sus aliases y entidades ambiguas

**Ejemplo**: "Luis Abinader", "Partido Revolucionario Moderno"

#### 2. **ALIAS**
Variante o alias de una entidad can√≥nica.

**Caracter√≠sticas**:
- Debe tener **exactamente 1** `canonical_ref`
- Su relevancia se **transfiere completamente** a la can√≥nica
- √ötil para abreviaturas, apodos, variantes de escritura

**Ejemplo**: "Luis" ‚Üí alias de "Luis Abinader"

**Transferencia de relevancia**:
```
Art√≠culo menciona: "Luis" (relevancia 0.8)
Sistema transfiere: "Luis Abinader" recibe +0.8 de relevancia
```

#### 3. **AMBIGUOUS**
Entidad ambigua que puede referirse a m√∫ltiples entidades can√≥nicas.

**Caracter√≠sticas**:
- Debe tener **m√≠nimo 2** `canonical_refs`
- Su relevancia se **divide equitativamente** entre las can√≥nicas presentes en el art√≠culo
- El sistema intenta resolver autom√°ticamente usando contexto

**Ejemplo**: "Luis" ‚Üí puede ser "Luis Abinader" o "Luis Fonsi"

**Divisi√≥n de relevancia**:
```
Art√≠culo menciona: "Luis" (relevancia 0.6), "el presidente" (alias de Luis Abinader)
Sistema detecta contexto: Solo Luis Abinader est√° presente
Resultado: Luis Abinader recibe +0.6 (no se divide)
```

#### 4. **NOT_AN_ENTITY**
Falso positivo de extracci√≥n (no es realmente una entidad).

**Caracter√≠sticas**:
- No puede tener `canonical_refs`
- Su relevancia siempre es **0.0** (ignorada completamente)
- √ötil para limpiar detecciones err√≥neas del LLM

**Ejemplo**: "D√≠a" detectado como entidad pero es palabra com√∫n

### Desambiguaci√≥n Contextual Autom√°tica

Cuando el sistema encuentra una entidad **AMBIGUOUS** en un art√≠culo, intenta resolverla autom√°ticamente:

**Estrategia de resoluci√≥n**:

1. **B√∫squeda directa**: ¬øSe menciona la can√≥nica expl√≠citamente?
   - Si el art√≠culo menciona "Luis Abinader" ‚Üí resuelto como "Luis Abinader"

2. **B√∫squeda por referencias**: ¬øHay otros alias que apuntan a esta can√≥nica?
   - Si el art√≠culo menciona "el presidente" (ALIAS de "Luis Abinader") ‚Üí resuelto como "Luis Abinader"

3. **Si no se puede resolver**:
   - Si tiene ‚â§ 10 canonicals ‚Üí divide relevancia entre todas
   - Si tiene > 10 canonicals ‚Üí ignora completamente (evita diluci√≥n excesiva)

**L√≠mites de rendimiento**:
```python
MAX_CONTEXTUAL_RESOLUTION_REFS = 10  # M√°ximo para intentar resoluci√≥n contextual
MAX_AMBIGUITY_THRESHOLD = 10  # Ignorar si tiene m√°s de este n√∫mero de canonicals
```

### Origen de Entidades (EntityOrigin)

El campo `article_entities.origin` distingue c√≥mo lleg√≥ la entidad al art√≠culo:

- **`AI_ANALYSIS`**: Detectada por OpenAI durante `analyze_article`
- **`CLASSIFICATION`**: Agregada autom√°ticamente por el sistema de clasificaci√≥n al resolver aliases/ambiguos

**Ejemplo**:
```
Art√≠culo original (AI_ANALYSIS): "Luis" (3 menciones)
Clasificas: "Luis" como ALIAS de "Luis Abinader"
Sistema agrega artificialmente: "Luis Abinader" con origin=CLASSIFICATION
```

**Protecci√≥n contra duplicaci√≥n**: Si "Luis Abinader" ya fue detectado por AI_ANALYSIS, NO se agrega artificialmente otra vez (evita duplicar link juice).

### Clasificaci√≥n Autom√°tica con IA

El sistema ofrece clasificaci√≥n automatizada usando **LSH (Locality-Sensitive Hashing) + Comparaci√≥n 1v1 con OpenAI**.

#### Comando: `ai-classify`

```bash
# Clasificar todas las entidades
uv run news entity ai-classify

# Clasificar solo un tipo de entidad
uv run news entity ai-classify --type PERSON

# Ver qu√© har√≠a sin ejecutar
uv run news entity ai-classify --dry-run

# Con verbose logging
uv run news entity ai-classify --verbose

# Ajustar umbral LSH (default 0.7)
uv run news entity ai-classify --lsh-threshold 0.8
```

#### Proceso de Clasificaci√≥n AI

**FASE 1: Descubrimiento de Candidatos con LSH**
- Convierte nombres de entidades a caracteres individuales
- Genera MinHash signatures (128 permutaciones)
- Encuentra pares similares usando umbral configurable (default 0.7)
- **No requiere llamadas a API** - puramente algor√≠tmico

**FASE 2: Comparaci√≥n Sem√°ntica con OpenAI**
- Para cada par candidato, llama OpenAI para an√°lisis sem√°ntico
- Carga pares ya comparados desde `entity_pair_comparisons`
- **Evita re-testar** pares ya procesados (ahorro de costos API)
- Analiza contexto, nombres, y tipos de entidad

**FASE 3: Aplicaci√≥n de Clasificaciones**
El LLM puede clasificar una entidad como:
- **ALIAS**: Variante/abreviatura ‚Üí llama `set_as_alias()`
- **AMBIGUOUS**: Puede referirse a m√∫ltiples ‚Üí llama `set_as_ambiguous()`
- **NOT_AN_ENTITY**: Falso positivo ‚Üí llama `set_as_not_entity()`
- **NO_CHANGE**: Son entidades diferentes ‚Üí no hace nada

**FASE 4: Guardado de Comparaciones**
- Cada comparaci√≥n se guarda en `entity_pair_comparisons`
- Incluye: relaci√≥n (SAME/DIFFERENT/AMBIGUOUS), confianza, razonamiento
- Relaci√≥n derivada de los cambios de clasificaci√≥n
- Evita duplicados con √≠ndice √∫nico en `(entity_a_id, entity_b_id)`

**Beneficios del tracking de pares**:
- ‚úÖ No re-testa pares ya comparados (ahorro de costos)
- ‚úÖ Historial completo de decisiones del LLM
- ‚úÖ Permite audit trail y revisi√≥n manual
- ‚úÖ Puede usarse para entrenar modelos futuros

```sql
-- Ver todas las comparaciones
SELECT * FROM entity_pair_comparisons;

-- Ver solo entidades consideradas iguales
SELECT * FROM entity_pair_comparisons WHERE relationship = 'SAME';

-- Ver comparaciones con baja confianza
SELECT * FROM entity_pair_comparisons WHERE confidence < 0.7;
```

### Comandos de Clasificaci√≥n Manual

Si necesitas clasificar manualmente (alternativa o complemento a `ai-classify`):

#### Listar entidades pendientes de revisi√≥n
```bash
uv run news entity list --needs-review
```

#### Revisar entidad espec√≠fica
```bash
uv run news entity review <entity_id>
```

Muestra contexto de la entidad y opciones interactivas para clasificar.

#### Clasificar como CANONICAL
```bash
uv run news entity classify-canonical <entity_id>
```

#### Clasificar como ALIAS
```bash
uv run news entity classify-alias <entity_id> <canonical_id>
```

**Ejemplo**:
```bash
# "Luis" (ID: 123) es alias de "Luis Abinader" (ID: 45)
uv run news entity classify-alias 123 45
```

#### Clasificar como AMBIGUOUS
```bash
uv run news entity classify-ambiguous <entity_id> <canonical_id_1> <canonical_id_2> [...]
```

**Ejemplo**:
```bash
# "Luis" puede ser Luis Abinader (45) o Luis Fonsi (67)
uv run news entity classify-ambiguous 123 45 67
```

#### Clasificar como NOT_AN_ENTITY
```bash
uv run news entity classify-not-entity <entity_id>
```

### Recalculaci√≥n de Relevancia Local

Despu√©s de clasificar entidades, **debes recalcular** la relevancia local de los art√≠culos afectados:

```bash
# Recalcular todos los art√≠culos marcados
uv run news entity recalculate-local

# Recalcular con l√≠mite
uv run news entity recalculate-local --limit 100

# Recalcular art√≠culo espec√≠fico
uv run news entity recalculate-local --article-id 456
```

**Proceso interno**:
1. Lee art√≠culos de `articles_needs_rerank`
2. Para cada art√≠culo:
   - Carga entidades originales (filtra por `origin=AI_ANALYSIS`)
   - Borra todas las relaciones `article_entities`
   - Recalcula relevancia con clasificaciones actuales
   - Inserta nuevas relevances con `origin` flags
3. Limpia art√≠culos procesados de `articles_needs_rerank`

**Stats mostradas**:
- Articles processed/failed
- Total entities
- Entities ignored (ALIAS/AMBIGUOUS/NOT_AN_ENTITY)
- Entities artificial (from classifications)

### Tabla de Tracking

**`articles_needs_rerank`**: Art√≠culos que necesitan rec√°lculo.

Cuando clasificas una entidad, el sistema **autom√°ticamente** marca todos los art√≠culos que la mencionan:

```python
# M√©todo interno llamado por todos los set_as_*()
def _mark_articles_for_rerank(self, session):
    # Inserta en articles_needs_rerank todos los art√≠culos
    # que contienen esta entidad
```

### M√©todos Helper del Modelo

**IMPORTANTE**: Los cambios de clasificaci√≥n **deben hacerse** mediante estos m√©todos (no directamente):

```python
# En src/db/models.py clase NamedEntity

entity.set_as_canonical(session)
entity.set_as_alias(canonical_entity, session)
entity.set_as_ambiguous([canonical1, canonical2], session)
entity.set_as_not_entity(session)
```

**Estos m√©todos garantizan**:
- Validaci√≥n de restricciones (conteo de canonical_refs)
- Limpieza de relaciones existentes
- Marcado autom√°tico de art√≠culos para rerank
- Consistencia de datos

### Flujo Completo de Desambiguaci√≥n

#### Opci√≥n 1: Clasificaci√≥n Autom√°tica con IA (Recomendado)

```bash
# 1. Extraer entidades de art√≠culos con OpenAI
uv run news process start -t analyze_article

# 2. Ejecutar clasificaci√≥n AI-assisted
uv run news entity ai-classify --verbose

# Output:
# üîç Starting AI-assisted entity classification...
# üìä Found 150 entities to classify (type: ALL)
# üîç LSH candidate discovery...
# ‚úì Found 45 candidate pairs (threshold: 0.7)
#
# ü§ñ AI semantic comparison (1v1)...
# ‚úì Compared 45 pairs, classified 12 entities
#
# üìù Classification summary:
#    ‚Ä¢ 8 entities ‚Üí ALIAS
#    ‚Ä¢ 2 entities ‚Üí AMBIGUOUS
#    ‚Ä¢ 2 entities ‚Üí NOT_AN_ENTITY
#
# ‚úÖ Classification complete!

# 3. Recalcular relevancia local (si hubo cambios)
uv run news entity recalculate-local

# 4. Recalcular relevancia global (PageRank)
uv run news entity rerank

# 5. Ver entidades m√°s relevantes
uv run news entity list --order-by global_rank --limit 20
```

#### Opci√≥n 2: Clasificaci√≥n Manual

**Ejemplo real**: Desambiguar "Luis" manualmente

```bash
# 1. Identificar entidad ambigua
uv run news entity search "Luis"

# Output:
# ID: 123 | Name: Luis | Type: PERSON | Articles: 45

# 2. Buscar candidatos can√≥nicos
uv run news entity search "Luis Abinader"
uv run news entity search "Luis Fonsi"

# Output:
# ID: 45 | Name: Luis Abinader | Type: PERSON | Articles: 120
# ID: 67 | Name: Luis Fonsi | Type: PERSON | Articles: 8

# 3. Clasificar como AMBIGUOUS
uv run news entity classify-ambiguous 123 45 67

# Output:
# ‚úì Marked 'Luis' as AMBIGUOUS with 2 canonical references
# ‚úì 45 articles marked for local relevance recalculation

# 4. Recalcular relevancia local
uv run news entity recalculate-local --limit 50

# Output:
# üîÑ Recalculating local entity relevance...
# üìä Found 45 articles to process
# ...
# ‚úÖ Recalculation complete!
#    ‚Ä¢ Articles processed: 45
#    ‚Ä¢ Entities artificial: 67 (from AMBIGUOUS resolution)

# 5. Recalcular relevancia global (PageRank)
uv run news entity rerank

# 6. Verificar resultados
uv run news entity show "Luis Abinader"
uv run news entity show "Luis Fonsi"
```

### Validaci√≥n de Consistencia

Verificar manualmente la consistencia de una entidad:

```python
from db import Database, NamedEntity

db = Database()
session = db.get_session()

entity = session.query(NamedEntity).filter_by(id=123).first()
is_valid, errors = entity.validate_classification(session)

if not is_valid:
    for error in errors:
        print(f"ERROR: {error}")
```

**Restricciones validadas**:
- CANONICAL: 0 canonical_refs salientes
- ALIAS: Exactamente 1 canonical_ref
- AMBIGUOUS: M√≠nimo 2 canonical_refs
- NOT_AN_ENTITY: 0 canonical_refs

---

## Sistema de Grupos de Entidades

### Introducci√≥n

El sistema de grupos permite representar entidades colectivas (bandas, equipos, consejos) que tienen miembros individuales. Los grupos tienen tracking temporal de membres√≠as con fechas de inicio/fin y roles.

### Concepto

Un grupo es una entidad can√≥nica marcada con `is_group=1` que puede tener relaciones con otras entidades (sus miembros) a trav√©s de la tabla `entity_group_members`.

**Caracter√≠sticas:**
- Solo entidades CANONICAL pueden ser grupos
- Los miembros pueden ser cualquier entidad (incluso otros grupos)
- Cada membres√≠a tiene fecha de inicio/fin opcional
- Se valida que no haya overlaps (per√≠odos superpuestos) para el mismo miembro

**Casos de uso:**
- **M√∫sica:** "Wisin & Yandel" ‚Üí [Wisin, Yandel]
- **Pol√≠tica:** "Consejo de Ministros" ‚Üí [Ministro de Salud, Ministro de Educaci√≥n, ...]
- **Empresas:** "Microsoft" ‚Üí [Satya Nadella, Bill Gates, ...]

### Estructura de Datos

#### Flag `is_group`
```python
# En NamedEntity
is_group = Column(Integer, nullable=False, default=0, index=True)
# 0 = Entidad individual
# 1 = Grupo que puede tener miembros
```

#### Tabla `entity_group_members`
```sql
CREATE TABLE entity_group_members (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    group_id INTEGER REFERENCES named_entities(id) ON DELETE CASCADE,
    member_id INTEGER REFERENCES named_entities(id) ON DELETE CASCADE,
    role VARCHAR(100),           -- Opcional: "vocalist", "CEO", etc.
    since DATETIME,              -- Fecha de inicio (NULL = desconocido/siempre)
    until DATETIME,              -- Fecha de fin (NULL = presente/activo)
    created_at DATETIME,
    updated_at DATETIME
);
```

**Caracter√≠sticas:**
- PK auto-incremental (permite m√∫ltiples per√≠odos para el mismo member)
- Sin unique constraint (permite que un miembro salga y vuelva a entrar)
- Validaci√≥n de overlaps a nivel de aplicaci√≥n

### Gesti√≥n de Grupos

#### Marcar como grupo
```bash
# Solo entidades CANONICAL pueden ser grupos
uv run news entity set-group <entity_id>
```

#### Desmarcar como grupo
```bash
# Requiere que no tenga miembros
uv run news entity unset-group <entity_id>
```

#### Agregar miembro
```bash
# Miembro actualmente activo (since=NULL, until=NULL)
uv run news entity add-member <group_id> <member_id>

# Con rol y fechas
uv run news entity add-member 100 101 \
    --role "vocalist" \
    --since 1997-01-01 \
    --until 2011-07-01
```

**Validaci√≥n:**
- El grupo debe tener `is_group=1`
- El miembro debe existir en la base de datos
- No puede haber overlap con membres√≠as existentes

#### Remover miembro
```bash
# Marca la fecha de salida (actualiza until del registro activo)
uv run news entity remove-member <group_id> <member_id>

# Con fecha espec√≠fica
uv run news entity remove-member 100 101 --until 2011-07-01
```

#### Listar miembros
```bash
# Todos los miembros (todos los per√≠odos)
uv run news entity list-members <group_id>

# Miembros activos en fecha espec√≠fica
uv run news entity list-members 100 --active-at 2008-01-01

# Con detalles de fechas y roles
uv run news entity list-members 100 --show-dates
```

### Queries Temporales

#### Obtener miembros activos en una fecha
```python
# En c√≥digo (usando m√©todos helper)
article_date = article.published_date
active_members = group.get_active_members_at(article_date, session)

# SQL equivalente
SELECT ne.*
FROM named_entities ne
JOIN entity_group_members egm ON ne.id = egm.member_id
WHERE egm.group_id = :group_id
  AND (egm.since IS NULL OR egm.since <= :date)
  AND (egm.until IS NULL OR egm.until >= :date)
```

#### Obtener grupos de un miembro en una fecha
```python
active_groups = member.get_active_groups_at(article_date, session)
```

### Ejemplo Completo

**Escenario:** Aventura (grupo musical)

```bash
# 1. Buscar entidades
uv run news entity search "Aventura"  # ID: 100
uv run news entity search "Romeo Santos"  # ID: 101
uv run news entity search "Henry Santos"  # ID: 102

# 2. Marcar Aventura como grupo
uv run news entity set-group 100

# 3. Agregar miembros hist√≥ricos
uv run news entity add-member 100 101 \
    --role "lead vocalist" \
    --since 1997-01-01 \
    --until 2011-07-01  # Romeo sali√≥ en 2011

uv run news entity add-member 100 102 \
    --role "vocalist" \
    --since 1997-01-01  # Henry sigue activo (until=NULL)

# 4. Ver miembros en diferentes fechas
uv run news entity list-members 100 --active-at 2008-01-01
# Output: Romeo Santos, Henry Santos (ambos activos)

uv run news entity list-members 100 --active-at 2024-01-01
# Output: Henry Santos (solo Henry activo)

# 5. Ver informaci√≥n del grupo
uv run news entity show "Aventura"
# Output incluye: Group: Yes (2 member(s))

# 6. Ver informaci√≥n de un miembro
uv run news entity show "Romeo Santos"
# Output incluye: Member of 1 group(s)
```

### Boost de Relevancia (Futuro)

**Estado actual:** Los grupos NO afectan la relevancia de miembros ni viceversa.

**Implementaci√≥n futura:** Cuando se implemente boost bidireccional:
- Mencionar grupo ‚Üí boost a miembros activos en la fecha del art√≠culo
- Mencionar miembro ‚Üí boost al grupo si era miembro activo
- Boost con conservaci√≥n de suma (no infla relevancia total)

Ver dise√±o detallado en discusiones de desarrollo.

---

## Relevancia Global de Entidades (PageRank)

### Concepto

El sistema calcula la importancia global de entidades usando el algoritmo **PageRank** aplicado a un grafo de co-ocurrencias. La intuici√≥n es que entidades mencionadas juntas en art√≠culos forman una red de relaciones, donde:

- **Nodos**: Entidades (personas, organizaciones, lugares, etc.)
- **Aristas dirigidas ponderadas**: Co-ocurrencia en art√≠culos
  - Peso del enlace B ‚Üí A = `relevance_local(A)` en ese art√≠culo
  - Esto significa que "enlazas m√°s fuerte" a las figuras centrales de cada art√≠culo

**Ejemplo**: Si "Luis Abinader" (relevancia 1.0) y "Ministerio de Salud" (relevancia 0.76) aparecen en el mismo art√≠culo:
- Ministerio ‚Üí Abinader: peso 1.0 (Abinader es m√°s central)
- Abinader ‚Üí Ministerio: peso 0.76 (Ministerio es secundario)

### Tipos de Entidades Rankeadas

El c√°lculo de PageRank se aplica **solo** a los siguientes tipos de entidades:

- `PERSON`: Personas
- `ORG`: Organizaciones, instituciones
- `FAC`: Edificios, infraestructura
- `GPE`: Lugares geopol√≠ticos (pa√≠ses, ciudades)
- `LOC`: Ubicaciones geogr√°ficas
- `EVENT`: Eventos nombrados
- `WORK_OF_ART`: Obras de arte
- `LAW`: Leyes y documentos legales
- `LANGUAGE`: Idiomas
- `DATE`: Fechas

Los dem√°s tipos (MONEY, PERCENT, QUANTITY, etc.) mantienen `global_relevance = 0.0`.

### Algoritmo

**PageRank Iterativo**:
```
1. Inicializaci√≥n:
   - Si existe ranking previo: usar scores `pagerank` anteriores (warm start)
   - Nuevas entidades: inicializar en midpoint = (max + min) / 2 (convergencia m√°s r√°pida)
   - Normalizar vector inicial

2. Iteraci√≥n (hasta convergencia, max 1000 iteraciones, o timeout 30s):
   PR_new(i) = (1-d)/N + d * Œ£(PR(j) * w(j‚Üíi) / Œ£w(j‚Üík))

   Donde:
   - d = damping factor (0.85 por defecto)
   - N = n√∫mero total de entidades
   - w(j‚Üíi) = peso del enlace de j a i

3. Normalizar: Œ£ PR(i) = 1.0

4. Verificar convergencia: |PR_new - PR| < 1e-6

5. Verificar timeout: Si han pasado 30s, terminar gracefully
   (No genera error, simplemente guarda el estado actual)

6. Post-procesamiento:
   - Guardar resultado raw como `pagerank`
   - Normalizar con min-max scaling ‚Üí `global_relevance` (0.0-1.0)
```

**Dos M√©tricas de Ranking**:
- **`pagerank`**: Score raw (distribuci√≥n de probabilidad, suma ‚âà 1.0)
  - Usado para warm start en futuros c√°lculos
  - Preserva la distribuci√≥n original del algoritmo
- **`global_relevance`**: Score normalizado con min-max scaling (0.0-1.0)
  - Entidad m√°s importante = 1.0
  - Entidad menos importante = 0.0
  - Human-friendly, f√°cil de interpretar
  - √ötil para c√°lculos avanzados y comparaciones

**Manejo de Dangling Nodes**:
- Entidades sin enlaces salientes distribuyen su probabilidad uniformemente

**Ajustes del Algoritmo**:
- **Max iteraciones**: 1000 (suficiente para convergencia en la mayor√≠a de casos)
- **Timeout graceful**: 30 segundos (no genera error, guarda estado actual)
- **Threshold de relevancia**: Ignorar co-ocurrencias d√©biles (default: 0.3)
- **Normalizaci√≥n por documento**: Siempre activa (divide peso por # entidades/art√≠culo)
- **Time decay**: Dar menos peso a art√≠culos antiguos (exponencial, opcional)

### M√©tricas Calculadas

Se calculan y almacenan las siguientes m√©tricas en `named_entities`:

- **pagerank**: Score PageRank raw (suma ‚âà 1.0 entre todas las entidades)
- **global_relevance**: PageRank normalizado 0.0-1.0 (min-max scaled)
- **article_count**: N√∫mero de art√≠culos donde aparece
- **avg_local_relevance**: Promedio de relevancia local
- **diversity**: N√∫mero de entidades √∫nicas con las que co-ocurre

### Comando CLI

```bash
uv run news entity rerank [OPTIONS]
```

**Opciones**:
- `--domain TEXT`: Filtrar art√≠culos por dominio (testing)
- `--damping FLOAT`: Factor de amortiguaci√≥n (default: 0.85)
- `--threshold FLOAT`: Umbral m√≠nimo de relevancia (default: 0.3)
- `--time-decay INT`: Decay temporal en d√≠as (opcional)
- `--show-stats`: Mostrar estad√≠sticas detalladas

**Ejemplos**:
```bash
# Calcular ranking global para todas las entidades
uv run news entity rerank

# Solo art√≠culos de un dominio (testing)
uv run news entity rerank --domain diariolibre.com

# Ajustar par√°metros del algoritmo
uv run news entity rerank --damping 0.9 --threshold 0.4

# Con decay temporal y estad√≠sticas
uv run news entity rerank --time-decay 30 --show-stats
```

**Output esperado**:
```
üîÑ Calculating global entity relevance...

üìä Loading data:
   ‚Ä¢ 1,234 enriched articles
   ‚Ä¢ 567 entities to rank

‚öôÔ∏è  Executing PageRank...
   ‚Ä¢ Damping: 0.85
   ‚Ä¢ Threshold: 0.3

‚úÖ Global relevance calculated successfully!

   ‚Ä¢ Converged in 23 iterations
   ‚Ä¢ Processing time: 2.45s
   ‚Ä¢ Entities ranked: 567

üèÜ Top 10 entities by global relevance:

    1. Luis Abinader - 0.084723
    2. Joe Biden - 0.062384
    3. Ministerio de Salud - 0.051234
    ...

üíæ Updated database

üí° View ranked entities with:
   news entity list --order-by global_rank
```

### Ver Resultados

**Listar por ranking global**:
```bash
uv run news entity list --order-by global_rank --limit 20
```

**Ver detalles de entidad**:
```bash
uv run news entity show "Luis Abinader"
```

Output incluye:
- Global Rank: `0.084723 (#1 of 567)`
- Avg Local Relevance: `0.856`
- Diversity: `123 co-occurring entities`

### Consultas SQL

**Top entidades por PageRank**:
```sql
SELECT
    name,
    entity_type,
    pagerank,
    global_relevance,
    article_count,
    avg_local_relevance,
    diversity
FROM named_entities
WHERE global_relevance > 0
ORDER BY global_relevance DESC
LIMIT 20;
```

**Distribuci√≥n de scores**:
```sql
SELECT
    entity_type,
    COUNT(*) as total,
    AVG(global_relevance) as avg_rank,
    MAX(global_relevance) as max_rank,
    SUM(CASE WHEN global_relevance > 0.01 THEN 1 ELSE 0 END) as influential
FROM named_entities
WHERE global_relevance > 0
GROUP BY entity_type
ORDER BY avg_rank DESC;
```

**Entidades con mayor conectividad**:
```sql
SELECT
    name,
    entity_type,
    diversity,
    article_count,
    global_relevance
FROM named_entities
WHERE diversity > 0
ORDER BY diversity DESC
LIMIT 20;
```

### Frecuencia de Actualizaci√≥n

El ranking global **no se calcula autom√°ticamente**. Se debe ejecutar manualmente con `news entity rerank`.

**Recomendaciones**:
- **Diario**: Para portales de noticias en producci√≥n
- **Despu√©s de procesar lotes grandes**: Si se agregan 100+ art√≠culos nuevos
- **Semanal**: Para desarrollo/testing

### Validaci√≥n

Despu√©s de calcular el ranking, verificar:

1. **Suma de probabilidades**: `SUM(pagerank) ‚âà 1.0` (distribuci√≥n de PageRank)
2. **Normalizaci√≥n**: `MAX(global_relevance) = 1.0` y `MIN(global_relevance) = 0.0`
3. **Top entidades coherentes**: Presidentes, ministros, organizaciones principales deben tener scores altos
4. **Convergencia**: El algoritmo debe converger en <100 iteraciones t√≠picamente
   - Si llega a 1000 iteraciones o 30s timeout, revisar datos de entrada
5. **Distribuci√≥n**: La entidad m√°s importante debe tener `global_relevance = 1.0`

### Consideraciones de Performance

- **~1000 entidades**: Matriz 1000√ó1000, procesa en <5 segundos
- **10k+ entidades**: Considerar:
  - Usar sparse matrices (`scipy.sparse`)
  - Filtrar por tiempo (√∫ltimos N meses)
  - Incrementar threshold de relevancia

**Memoria estimada**:
- 1000 entidades: ~8 MB (matriz densa)
- 10000 entidades: ~800 MB

